{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanu-N-Prabhu/Python/blob/master/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg3lvf8hpY2z",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "                 \n",
        "                 \n",
        "                 CS 890 AC - Data Analysis from the Internet\n",
        "                     Due: Tuesday 4th June 2019 11:59 PM\n",
        "                         Instructor: Trevor Tomesh\n",
        "                           By: Tanu Nanda Prabhu\n",
        "                           Student id - 200409072\n",
        "                                 Points: 10 \n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoPS7bG3Y9IE",
        "colab_type": "text"
      },
      "source": [
        "# Homework 1\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAXP06JnpB-I",
        "colab_type": "text"
      },
      "source": [
        "**In this assignment, we will use the python requests library and BeautifulSoup to scrape raw\n",
        "data from unrefined HTML source code. We will build a data science laboratory on the google\n",
        "colab jupyter notebook environment beginning with these webscraping tools.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFIe-tL3qCmx",
        "colab_type": "text"
      },
      "source": [
        "# Part A - Define the Problem\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWUTzv_DqQs5",
        "colab_type": "text"
      },
      "source": [
        " **Before addressing your problem, you must first defne it. For this assignment, you may choose one of the following tasks:**\n",
        " \n",
        "\n",
        "\n",
        ">**1. Scrape two youtube accounts and report the subscriber difference.**\n",
        "\n",
        ">**2. Scrape a twitter account to find a keyword (or keywords) of interest.**\n",
        "\n",
        "\n",
        "**In your jupiter notebook, write a paragraph describing in some detail the problem you\n",
        "have chosen. This should include the name(s) of the accounts that you are scraping\n",
        "and what you are looking for and why ?**\n",
        "\n",
        "\n",
        "> <p align=\"justify\"> I have chosen to scrape two YouTube accounts, named “PewDiePie” and “T-Series,” and report the subscriber difference. I have been a diehard fan of PewDiePie for the past 4 years, and he was the number one YouTuber in terms of his subscribers, up until the last six to ten months. At this point, T-series arrived and eventually outperformed and dethroned PewDiePie, setting a record and becoming the most subscribed channel (apart from YouTube’s own music channel). I did not like T-Series taking over, or how the sub-gap between T-Series and PewDiePie continues to increase drastically. In addition, this subscription gap was one of the biggest controversies in YouTube’s history, which is another reason why I chose to scrape this data. I have a strong feeling that eventually PewDiePie will surpass T-Series again, and remain as the number one YouTuber forever. Scraping these accounts and determining the subscriber gap will allow me to state with accuracy how close PewDiePie is to regain the title of the most subscribed YouTuber.</p>\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBm9qx_KqWx7",
        "colab_type": "text"
      },
      "source": [
        "# Part B - Exploring the Source Code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5u5cY7wqeq9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**To use BeautifulSoup, you will need to identify the HTML tag and element that you are\n",
        "trying to scrape**\n",
        "\n",
        "\n",
        "\n",
        "> **1. In your jupiter notebook, document how / where you found the appropriate tags/elements.**\n",
        "\n",
        ">**2. Include a screenshot with your explanation.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03SLx2EUKm6K",
        "colab_type": "text"
      },
      "source": [
        "> <p align=\"justify\"> To find the HTML tags, you must locate both PewDiePie and T-Series YouTube channels. After locating the channels find for the total numbers of subscribers on the page, which would be displayed right below their respected channel names. When you get this right click on that subscribers and then click on Inspect option or (Ctrl-Shift-I), a new page along with the selected tag will open to your right next to the page. And there you go you can see the HTML tag and the element. Below I have included a screenshot of PewDiePie’s channel along with the tags. The same continues to T-Series's channel as it is a mechanical process, follow the same to do it, so which is why I just included only PewDiePie’s channel. </p>\n",
        "\n",
        "<center><img src=\"http://i63.tinypic.com/2nkpet1.png\" width = 900 height = 500></center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jcNfFy6Qx20",
        "colab_type": "text"
      },
      "source": [
        "><p align = \"justify\">In the above screenshot the tags are <b>“yt-formatted-string” </b>it’s a custom YouTube tag, unfortunately, this doesn’t work. I mean that when I scraped this the soup.findAll method returned an empty pair of brackets ([ ]) and I don’t know why maybe it’s because of the custom tag and not the regular HTML tag. So, solving this, I just had to look at what is actually being scraped meaning I tried to see what BeautifulSoup is actually returning then I got the answer, soup is actually printing a bit different from the raw HTML, then I searched for the keyword i.e. Subscribers (96, 197, 730) inside the soup using Ctrl-F and then I got the actual HTML tags and the elements. Shown below is the final screenshot of the problem. The actual HTML tag is span and the class is <b>“yt-subscription-button-subscriber-count-branded-horizontal subscribed yt-uix-tooltip.”</b></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx1judwfQcqK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "<center><img src=\"http://i63.tinypic.com/s6850m.png\"  width = 800 height = 500></center>\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI6Bp7GXqnMF",
        "colab_type": "text"
      },
      "source": [
        "# Part C - Write the Scraper\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsLBhRUWqj8I",
        "colab_type": "text"
      },
      "source": [
        "**1. Start by importing requests and BeautifulSoup.**\n",
        "\n",
        "**2. Write a function that will take a URL and return the isolated text (no HTML, etc.)**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAW65Je1bYoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsaM5Djub7bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://www.youtube.com/user/PewDiePie'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qJNC1T7qdck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url2 = 'https://www.youtube.com/user/tseries'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bxta4rTcFhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page = requests.get(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvihGXapqfhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page2 = requests.get(url2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5Ad-3jbcMvK",
        "colab_type": "code",
        "outputId": "14221158-48c2-47b9-8f9b-2ffb0f3deda9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(page)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Response [200]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XFASJ85-C6e",
        "colab_type": "code",
        "outputId": "55746acd-144d-4e2b-e8f4-b4adb2e9e4e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(page2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Response [200]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6MzwvRkcO5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = BeautifulSoup(page.text, \"html.parser\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSHm0Bv2qnYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup2 = BeautifulSoup(page2.text, \"html.parser\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIWAyJkWpNIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pew = soup.findAll(\"span\", {\"class\": \"yt-subscription-button-subscriber-count-branded-horizontal subscribed yt-uix-tooltip\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY4RcghdrOIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tseries = soup2.findAll(\"span\", {\"class\": \"yt-subscription-button-subscriber-count-branded-horizontal subscribed yt-uix-tooltip\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LDpE0aNpYki",
        "colab_type": "code",
        "outputId": "59f690f0-83f2-43d5-a82b-d6c643116034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(pew)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<span aria-label=\"96,197,730 subscribers\" class=\"yt-subscription-button-subscriber-count-branded-horizontal subscribed yt-uix-tooltip\" tabindex=\"0\" title=\"96,197,730\">96,197,730</span>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHCU_7F2rXTO",
        "colab_type": "code",
        "outputId": "f90d79fc-f29a-4c83-f457-be95126d1b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(tseries)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<span aria-label=\"100,057,202 subscribers\" class=\"yt-subscription-button-subscriber-count-branded-horizontal subscribed yt-uix-tooltip\" tabindex=\"0\" title=\"100,057,202\">100,057,202</span>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q_M7xh2pd1K",
        "colab_type": "code",
        "outputId": "c9040f4a-333c-4d77-ffd2-fe65bcbffd8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "for subs in pew:\n",
        "  print(subs.get_text())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96,197,730\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POQvvW7ZrcJG",
        "colab_type": "code",
        "outputId": "043b31a8-2af8-4ee6-9933-4193c45cc6bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "for subs1 in tseries:\n",
        "  print(subs1.get_text())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100,057,202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z0Nt32K9YBP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiVZdBBCqtTE",
        "colab_type": "text"
      },
      "source": [
        "# Part D - Process and Present\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOTNKId-quoM",
        "colab_type": "text"
      },
      "source": [
        "**1. Depending upon your problem, you will need to format the data that you have scraped\n",
        "and perform some sort of computation to answer the problem that you’ve specified in\n",
        "Part A.**\n",
        "\n",
        " **2. Present the information that you’ve uncovered and write a small summary of your\n",
        "findings. You will have to determine the best way to do this – but “keep it simple and\n",
        "keep it clear” is always a good heuristic. There should be no question as to what you\n",
        "are trying to convey.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vNt72EFiujK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "><p align = \"justify\">Formatting the scraped data was not an easy task because the values that were returned were a series of numbers separated by commas. Puzzled by this formatting issue, I used the website stack overflow, which helped me through one of their forums. In that forum, they discussed about replace (): gets rid of the commas, and the format (): helps in formatting the values. This removal of commas must be done because it was difficult to perform subtraction with commas. Additionally, these values were of type string and they needed to be explicitly converted to an integer by typecasting because it is not possible to subtract two strings. After typecasting, it was a one-step process of subtracting the two variables which contained integers in them. Hence, this is how I successfully obtained the sub difference by scraping the two YouTube channels.</p>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wPFB_hru04Y",
        "colab_type": "code",
        "outputId": "e0aac313-d6ac-484e-b74a-995e4cc7abfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pewdiepie = subs.get_text().replace(\",\", \"\")\n",
        "pewdiepie"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'96197730'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFFWPirau8dO",
        "colab_type": "code",
        "outputId": "737dd6bd-a18d-41e7-cc85-a1bcdc3cb0d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tseries = subs1.get_text().replace(\",\", \"\")\n",
        "tseries"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'100057202'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHAaluvAs9Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "difference = int(tseries) - int(pewdiepie)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fw-3DstvQNs",
        "colab_type": "code",
        "outputId": "0f46c9c4-8750-47be-9afd-24fc194e347f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "difference"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3859472"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCmc8fUqjbCC",
        "colab_type": "code",
        "outputId": "9c4bf918-fc7b-4bc8-8cac-465585636f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"The sub gap between T-series and PewDiePie is  ==> \"'{:,}'.format(difference))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sub gap between T-series and PewDiePie is  ==> 3,859,472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbippKuA9auY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}